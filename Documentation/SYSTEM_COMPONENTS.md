# System Components Explained

**Date:** January 7, 2026  
**Document Purpose:** Deep dive into each component's role and responsibilities

---

## ğŸ§© Component Overview

This document breaks down each component of the Infrastructure Automation Platform, explaining what it does, what it doesn't do, and how it fits into the overall architecture.

---

## ğŸ–¥ï¸ 1ï¸âƒ£ Frontend (React / Vite â€“ Windows)

**What it is:**
- The UI you see in the browser
- Runs on Windows
- Built with React + Vite
- Compiled JavaScript running in browser

**What it does:**
- âœ… Shows login page, dashboard, forms
- âœ… Takes user input (server details, playbook upload, run button)
- âœ… Sends requests to backend APIs
- âœ… Displays job status & results
- âœ… Manages local state (authentication tokens)
- âœ… Provides responsive, interactive UI

**What it does NOT do:**
- âŒ Does not run Ansible
- âŒ Does not talk to database
- âŒ Does not run background jobs
- âŒ Does not store sensitive data permanently
- âŒ Does not execute server commands

**Analogy:**
> ğŸ§‘â€ğŸ’» **Frontend = Customer at a counter**  
> Only talks to the shop counter, not to the storeroom or workers.

**Technology Stack:**
- React 18.2
- TypeScript 5.3
- Vite 5.0 (build tool)
- Zustand (state management)
- TailwindCSS (styling)
- Axios (HTTP client)

---

## ğŸŒ 2ï¸âƒ£ Backend (Flask API â€“ Linux VM)

**What it is:**
- Central brain of the system
- Runs on Linux VM
- Listens on port 5000
- Built with Flask (Python)

**What it does:**
- âœ… Exposes REST APIs (`/login`, `/jobs`, `/servers`, etc.)
- âœ… Authenticates users (JWT tokens)
- âœ… Validates all requests
- âœ… Enforces role-based access control
- âœ… Writes & reads data from database
- âœ… Triggers background jobs via Celery
- âœ… Returns JSON responses to frontend
- âœ… Handles file uploads (playbooks)
- âœ… Encrypts sensitive data (SSH keys)

**What it does NOT do:**
- âŒ Does not execute Ansible directly (delegates to Celery)
- âŒ Does not block waiting for long tasks
- âŒ Does not render HTML (API only)
- âŒ Does not connect to managed servers directly

**Analogy:**
> ğŸª **Backend = Shop counter / manager**  
> Takes order â†’ Writes order details â†’ Delegates heavy work to staff â†’ Updates customer with status

**Technology Stack:**
- Flask 3.0
- SQLAlchemy 2.0 (ORM)
- Flask-JWT-Extended (authentication)
- Marshmallow (validation)
- Bcrypt (password hashing)
- Python 3.10+

**Key Endpoints:**
```
POST   /api/auth/login          - User authentication
GET    /api/auth/me             - Get current user
POST   /api/servers             - Create server
GET    /api/servers             - List servers
POST   /api/playbooks/upload    - Upload playbook
POST   /api/jobs                - Create job
GET    /api/jobs/:id            - Get job status
GET    /api/jobs/:id/logs       - Get job logs
```

---

## ğŸ§µ 3ï¸âƒ£ Celery (Background Worker â€“ Linux VM)

**What it is:**
- Asynchronous task worker
- Runs alongside Flask (separate process)
- Handles long-running jobs
- Multiple workers can run in parallel

**What it does:**
- âœ… Picks up tasks sent by Flask via Redis
- âœ… Runs Ansible playbooks
- âœ… Processes job execution
- âœ… Handles log processing
- âœ… Updates job status in database
- âœ… Runs independently of user requests
- âœ… Can handle multiple jobs simultaneously
- âœ… Retries failed tasks (configurable)

**Why Celery is needed:**

**Without Celery:**
- âŒ Flask would freeze while Ansible runs (could be 10+ minutes)
- âŒ UI would hang and appear broken
- âŒ Users couldn't submit multiple jobs
- âŒ One long task blocks everything

**With Celery:**
- âœ… Flask returns immediately
- âœ… User can submit more jobs
- âœ… Jobs run in background
- âœ… Can scale with more workers

**Analogy:**
> ğŸ‘· **Celery = Worker staff**  
> Does the heavy lifting â†’ Works in background â†’ Reports progress back

**Technology Stack:**
- Celery 5.3
- Python 3.10+
- Ansible Runner 2.3

**How it works:**
```
1. Flask creates task: execute_playbook(job_id=123)
2. Task sent to Redis queue
3. Celery worker picks up task
4. Worker calls ansible_runner.run()
5. Worker updates database with status
6. Worker marks task complete
```

---

## ğŸ“¦ 4ï¸âƒ£ Redis (Message Queue â€“ Linux VM)

**What it is:**
- In-memory message broker
- Very fast (microsecond latency)
- Used by Celery for task queuing
- Simple key-value store

**What it does:**
- âœ… Acts as a queue between Flask and Celery
- âœ… Stores pending tasks
- âœ… Sends tasks from Flask â†’ Celery
- âœ… Stores task results/status (temporarily)
- âœ… Provides pub/sub for real-time updates
- âœ… Caches frequently accessed data

**What it does NOT do:**
- âŒ Does not store permanent data
- âŒ Does not know business logic
- âŒ Does not validate data
- âŒ Does not replace database

**Why Redis is needed:**

**Without Redis:**
- Flask and Celery can't communicate reliably
- Tasks could be lost
- No queue management
- Can't track task status

**Analogy:**
> ğŸ“¬ **Redis = Task inbox**  
> Flask drops job request â†’ Celery picks it up â†’ Simple, fast, reliable

**Technology Stack:**
- Redis 6.0+
- In-memory storage
- Persistence optional (RDB/AOF)

**Data stored (temporary):**
```
celery-task-meta-abc123: { status: "running", result: null }
celery:queue: [task1, task2, task3]
celery:results: { task1: "success", task2: "pending" }
```

---

## ğŸ—„ï¸ 5ï¸âƒ£ Database (MySQL / MariaDB)

**What it is:**
- Permanent storage
- Accessed only by backend
- Uses SQLAlchemy ORM
- Relational database

**What it stores:**
- **Users & roles** (authentication, permissions)
- **Servers & inventory** (hostnames, IPs, SSH credentials)
- **Playbook metadata** (names, paths, descriptions)
- **Job records** (status, start/end times, results)
- **Execution logs** (line-by-line output)
- **Audit logs** (who did what, when)
- **Tickets** (support requests, optional)

**What it does NOT do:**
- âŒ Does not run Ansible
- âŒ Does not talk to frontend directly
- âŒ Does not execute jobs
- âŒ Does not connect to managed servers

**Analogy:**
> ğŸ“š **Database = Storeroom / records**  
> Everything is saved here â†’ Backend decides what to read/write â†’ Source of truth

**Technology Stack:**
- MySQL 8.0+ or MariaDB 10.5+
- SQLAlchemy ORM
- PyMySQL driver

**Schema (7 tables):**

1. **users** - Authentication and user management
2. **servers** - Infrastructure inventory
3. **playbooks** - Ansible playbook metadata
4. **jobs** - Job execution tracking
5. **job_logs** - Line-by-line execution logs
6. **audit_logs** - Complete audit trail
7. **tickets** - Support ticket system (optional)

**Example queries:**
```sql
-- Get all running jobs
SELECT * FROM jobs WHERE status = 'running';

-- Get recent logs for a job
SELECT * FROM job_logs WHERE job_id = 123 ORDER BY created_at DESC LIMIT 100;

-- Get user's job history
SELECT * FROM jobs WHERE triggered_by = 1 ORDER BY created_at DESC;
```

---

## âš™ï¸ 6ï¸âƒ£ Ansible (Automation Engine â€“ Linux VM)

**What it is:**
- Infrastructure automation tool
- Executed by Celery workers
- Runs playbooks on managed servers
- Agentless (uses SSH)

**What it does:**
- âœ… Connects to target servers via SSH
- âœ… Executes automation tasks (deploy, configure, update)
- âœ… Generates execution logs
- âœ… Reports success/failure with details
- âœ… Runs idempotently (safe to re-run)
- âœ… Supports modules (apt, yum, copy, service, etc.)

**What it does NOT do:**
- âŒ Does not have a persistent UI
- âŒ Does not store data (we use database for that)
- âŒ Does not track jobs (Celery does that)
- âŒ Does not handle authentication (backend does)

**Analogy:**
> ğŸ”§ **Ansible = The actual tool**  
> Screwdriver in the worker's hand â†’ Does the real work

**Technology Stack:**
- Ansible Core 2.15+
- Ansible Runner 2.3 (Python API)
- SSH for connectivity

**How Celery uses Ansible:**
```python
import ansible_runner

result = ansible_runner.run(
    playbook='deploy-webapp.yml',
    inventory={'all': {'hosts': ['192.168.1.10']}},
    private_data_dir='/var/lib/ansible-runner',
)

print(result.status)  # 'successful' or 'failed'
print(result.rc)      # Return code
print(result.stdout)  # Execution output
```

---

## ğŸ”„ How All Components Work Together

### Complete Flow: User Runs a Playbook

```
1. User (Browser - Windows)
   ğŸ‘¤ Clicks "Run Playbook" button
   â†“

2. Frontend (React - Windows)
   ğŸ–¥ï¸ Sends HTTP POST request
   POST http://192.168.1.100:5000/api/jobs
   Body: { playbook_id: 1, server_id: 2 }
   â†“

3. Backend (Flask - Linux VM)
   ğŸŒ Receives request
   â€¢ Validates JWT token â†’ âœ…
   â€¢ Checks user has "operator" role â†’ âœ…
   â€¢ Validates server & playbook exist â†’ âœ…
   â€¢ Creates job record in database
   â€¢ Sends task to Redis queue
   â€¢ Returns: { job_id: 123, status: "pending" }
   â†“

4. Database (MySQL - Linux VM)
   ğŸ—„ï¸ Stores job record
   INSERT INTO jobs (playbook_id, server_id, status, triggered_by)
   VALUES (1, 2, 'pending', 1)
   â†’ job_id = 123
   â†“

5. Redis (Message Broker - Linux VM)
   ğŸ“¦ Stores task in queue
   LPUSH celery:queue "execute_playbook(job_id=123)"
   â†“

6. Celery Worker (Background - Linux VM)
   ğŸ§µ Picks up task from Redis
   â€¢ BRPOP celery:queue â†’ Got task!
   â€¢ Updates job: UPDATE jobs SET status='running' WHERE id=123
   â€¢ Calls Ansible Runner API
   â†“

7. Ansible Engine (Linux VM)
   âš™ï¸ Executes playbook
   â€¢ Reads playbook: /playbooks/deploy-webapp.yml
   â€¢ Connects to server: ssh ansible@192.168.1.10
   â€¢ Runs tasks:
     TASK [Update apt cache] ******************
     ok: [192.168.1.10]
     
     TASK [Install nginx] *********************
     changed: [192.168.1.10]
   â†“

8. Managed Server (192.168.1.10)
   ğŸ–¥ï¸ Executes commands
   â€¢ Receives SSH connection
   â€¢ Runs: apt-get update
   â€¢ Runs: apt-get install nginx
   â€¢ Returns output to Ansible
   â†“

9. Celery Worker (Linux VM)
   ğŸ§µ Processes results
   â€¢ Receives Ansible output
   â€¢ Inserts logs into database:
     INSERT INTO job_logs (job_id, message, timestamp)
     VALUES (123, 'TASK [Install nginx]', '2026-01-07 10:05:23')
   â€¢ Updates job status:
     UPDATE jobs SET status='success', completed_at=NOW()
     WHERE id=123
   â†“

10. Database (MySQL - Linux VM)
    ğŸ—„ï¸ Stores results
    â€¢ job_logs table: 50 lines of execution logs
    â€¢ jobs table: status='success', duration=180s
    â†“

11. Frontend (React - Windows)
    ğŸ–¥ï¸ Displays results
    â€¢ Polls every 2 seconds: GET /api/jobs/123
    â€¢ Receives: { status: "success", duration: 180 }
    â€¢ Updates UI: âœ… Deployment successful (3min)
    â€¢ Fetches logs: GET /api/jobs/123/logs
    â€¢ Displays in terminal viewer
```

---

## ğŸ”‘ Key Design Principles

### âœ… 1. Separation of Responsibilities

**Each component has one clear job:**

| Component | Primary Responsibility |
|-----------|----------------------|
| Frontend | User interaction & display |
| Backend | API & coordination |
| Celery | Heavy processing |
| Redis | Task queuing |
| Database | Data persistence |
| Ansible | Automation execution |

**Why this matters:**
- Easy to debug (know where to look)
- Easy to scale (add more of one component)
- Easy to maintain (change one without affecting others)

### âœ… 2. OS Independence

**Frontend OS â‰  Backend OS â†’ Totally fine:**

```
Windows (Frontend)
   â†“ HTTP (OS-agnostic)
Linux (Backend)
```

**Why this works:**
- Communication is network-based (HTTP/REST)
- OS doesn't matter for API calls
- Can run on different clouds, different data centers
- Can even split across continents

### âœ… 3. Scalability

**You can add more resources without changing code:**

**Scale Frontend:**
- Add CDN for static files
- Multiple frontend servers behind load balancer
- Browser caching

**Scale Backend:**
- Add more Flask instances
- Use load balancer (Nginx/HAProxy)
- Horizontal scaling

**Scale Celery:**
- Add more worker processes
- Add more worker machines
- Prioritize queues

**Scale Database:**
- Read replicas
- Vertical scaling (more RAM/CPU)
- Sharding (for very large scale)

**Scale Redis:**
- Redis Cluster for high availability
- Sentinel for failover
- Persistence for durability

### âœ… 4. Asynchronous Processing

**Long tasks don't block the system:**

**Synchronous (BAD):**
```
User â†’ Backend â†’ Wait 10 minutes â†’ Response
        â†“
    BLOCKED
```

**Asynchronous (GOOD):**
```
User â†’ Backend â†’ Immediate Response (job_id)
       â†“
       Celery (background processing)
       â†“
User polls for status
```

**Benefits:**
- User doesn't wait
- Can submit multiple jobs
- System stays responsive
- Better user experience

---

## ğŸ§  One-Line Summary for Each Component

| Component | One-Line Role |
|-----------|--------------|
| **Frontend** | UI & user interaction |
| **Backend (Flask)** | API & coordination |
| **Database** | Permanent data storage |
| **Redis** | Task queue / message broker |
| **Celery** | Background execution engine |
| **Ansible** | Actual infrastructure automation |

---

## ğŸ“Š Component Communication Matrix

| From â†’ To | Protocol | Purpose | Example |
|-----------|----------|---------|---------|
| Frontend â†’ Backend | HTTP/REST | API calls | `POST /api/jobs` |
| Backend â†’ Database | SQL | Data storage | `INSERT INTO jobs` |
| Backend â†’ Redis | Redis Protocol | Task queuing | `LPUSH task_queue` |
| Celery â†’ Redis | Redis Protocol | Get tasks | `BRPOP task_queue` |
| Celery â†’ Database | SQL | Update status | `UPDATE jobs SET status` |
| Celery â†’ Ansible | Python API | Execute playbooks | `ansible_runner.run()` |
| Ansible â†’ Servers | SSH | Run commands | `ssh user@server` |
| Frontend â†’ Browser | LocalStorage | Token storage | `localStorage.setItem()` |

---

## ğŸš¦ Why This Architecture Works

### 1. **Reliability**
- âœ… If Celery crashes â†’ Flask still works
- âœ… If Redis goes down â†’ Can restart without data loss
- âœ… Database has all permanent records
- âœ… Can restart any component independently

### 2. **Performance**
- âœ… Frontend doesn't wait for slow operations
- âœ… Redis is in-memory (microsecond latency)
- âœ… Multiple workers handle jobs in parallel
- âœ… Database queries are optimized with indexes

### 3. **Maintainability**
- âœ… Each component is independent
- âœ… Can update/restart one without affecting others
- âœ… Clear boundaries between services
- âœ… Easy to find and fix bugs

### 4. **Security**
- âœ… Database never exposed to internet
- âœ… Frontend never has DB credentials
- âœ… Backend validates everything
- âœ… JWT ensures authenticated requests
- âœ… SSH keys encrypted in database
- âœ… Role-based access control

---

## ğŸ¯ Summary

This architecture follows industry best practices:

- **3-tier architecture** (Presentation, Application, Data)
- **Microservices principles** (separation of concerns)
- **Asynchronous processing** (for long-running tasks)
- **API-first design** (frontend and backend decoupled)
- **Security by design** (defense in depth)

Each component does one thing well, and together they create a robust, scalable infrastructure automation platform.

---

**Document Version:** 1.0  
**Last Updated:** January 7, 2026  
**Status:** Component Deep Dive Complete
